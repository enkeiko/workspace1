# 📊 L1 데이터 수집 및 정렬 - 사용 가이드

## 개요

L1 모듈은 네이버 플레이스 크롤러로 수집한 원본 데이터를 분석 가능한 형태로 변환하고, 키워드 추출에 필요한 요소들을 체계적으로 분류하는 기능을 제공합니다.

## 주요 기능

### 1. 데이터 소스 통합
- 크롤러 JSON 파일 (필수)
- 현재 사용 중인 키워드 (권장)
- 수동 입력 메모 (선택)
- 경쟁사 정보 (선택)

### 2. 지역 정보 파싱
주소를 분석하여 다음 정보를 자동 추출합니다:
- 시/도 (예: 서울)
- 구/군 (예: 강남)
- 동/읍/면 (예: 역삼)
- 역 정보 (예: 강남역)

### 3. 키워드 요소 분류

#### 핵심 요소 (Core Elements)
- 카테고리: "닭갈비전문점" → "닭갈비"
- 서브카테고리: "전문점", "맛집" 등
- 브랜드명: "히도 강남점" → "히도"

#### 지역 요소 (Region Elements)
- 단일 지역: "강남", "강남역"
- 조합 지역: "강남 역삼", "강남역 인근"

#### 메뉴 요소 (Menu Elements)
- 전체 메뉴 목록
- 추천 메뉴
- 가격대 정보

#### 속성 요소 (Attribute Elements)
- 편의시설: 주차, 예약, WiFi 등
- 텍스트 변환: "주차 가능", "예약 가능"

### 4. 데이터 완성도 평가

총 115점 만점으로 평가:
- **필수 요소** (60점): 카테고리, 지역, 메뉴
- **중요 요소** (30점): 현재 키워드, 수동 타겟
- **보조 요소** (15점): 속성, 비즈니스 목표
- **추가 요소** (10점): 역 정보, 추천 메뉴

완성도 등급:
- **HIGH**: 90점 이상 (추천)
- **MEDIUM**: 60~89점 (보통)
- **LOW**: 60점 미만 (데이터 보완 필요)

## GUI 사용법

### 1. 서버 시작
```bash
cd Place_Crawler/V1
node gui-server.js
```

### 2. 브라우저에서 접속
```
http://localhost:3000
```

### 3. L1 데이터 수집 탭 이동
1. 상단 탭에서 "L1 데이터 수집" 클릭
2. 처리 단계 확인
3. "L1 처리 시작" 버튼 클릭

### 4. 실시간 로그 확인
- 자동으로 "디버그 로그" 탭으로 전환
- 처리 진행 상황 실시간 확인
- 색상별 로그 레벨:
  - 🔍 Debug (회색): 상세 디버그 정보
  - ℹ️ Info (녹색): 일반 정보
  - ⚠️ Warn (주황): 경고 메시지
  - ❌ Error (빨강): 오류 발생

### 5. 결과 확인
처리 완료 후 다음 정보가 표시됩니다:
- 총 매장 수
- 현재 키워드 보유 매장 수
- 평균 데이터 완성도
- 처리 시간
- 완성도 분포 (HIGH/MEDIUM/LOW)

## 입력 데이터 준비

### 필수: 크롤러 JSON
```
Place_Crawler/V1/places-advanced/
  ├── place-1768171911-FULL.json
  ├── place-1265317185-FULL.json
  └── ...
```

### 권장: 현재 키워드
```json
// Place_Crawler/V1/data/input/current_keywords.json
{
  "1768171911": {
    "primary_keywords": ["강남 닭갈비", "히도 강남점"],
    "secondary_keywords": ["강남 맛집"],
    "performance": {
      "avg_monthly_searches": 5000,
      "avg_click_rate": 0.15
    }
  }
}
```

### 선택: 수동 메모
```json
// Place_Crawler/V1/data/input/manual_notes.json
{
  "1768171911": {
    "target_keywords": ["닭갈비", "강남맛집"],
    "special_notes": "런치 세트 인기",
    "business_goals": "회식 고객 확대"
  }
}
```

## 출력 데이터

### 1. data_collected_l1.json
전체 수집 데이터 및 통계 정보
```
Place_Crawler/V1/data/output/l1/data_collected_l1.json
```

### 2. keyword_elements_l1.json
키워드 요소별 분류 결과
```
Place_Crawler/V1/data/output/l1/keyword_elements_l1.json
```

### 3. current_keywords_l1.json
현재 키워드 성능 분석 결과
```
Place_Crawler/V1/data/output/l1/current_keywords_l1.json
```

## 로그 기능

### 실시간 스트리밍
- Server-Sent Events (SSE)를 사용한 실시간 로그 전송
- 최대 5000개 로그 메모리 보관
- 파일 저장: `logs/gui-server.log`

### 필터링
체크박스로 로그 레벨별 필터링 가능:
- Debug, Info, Warn, Error

### 제어
- **일시정지/재개**: 로그 스트림 제어
- **로그 지우기**: 전체 로그 삭제

## 오류 해결

### E_L1_001: 크롤러 JSON 없음
**원인**: `places-advanced` 폴더에 JSON 파일이 없음
**해결**: 플레이스 수집기를 먼저 실행하여 데이터 수집

### E_L1_002: JSON 파싱 실패
**원인**: 손상된 JSON 파일
**해결**: 해당 파일 재수집 또는 삭제

### E_L1_003: 필수 필드 누락
**원인**: JSON에 id, name, category 필드 없음
**해결**: 크롤러 설정 확인 및 재수집

### E_L1_004: 주소 파싱 실패
**원인**: 비정상적인 주소 형식
**해결**: manual_notes.json에서 수동 보정

### E_L1_005: 데이터 완성도 낮음
**원인**: 수집 데이터 부족
**해결**: 현재 키워드 및 수동 메모 추가

## 성능 최적화

### 처리 속도
- 매장당 평균 0.3초
- 10개 매장 기준 약 3~5초
- 대용량 처리 시 메모리 사용량 약 50MB

### 권장 사항
1. 크롤러 실행 전 네이버플레이스 정보 최신화
2. 현재 키워드 데이터 정기 업데이트
3. 수동 메모에 비즈니스 목표 명확히 기재
4. 주기적인 로그 파일 백업

## CLI 사용법 (추후 지원 예정)

```bash
# L1만 실행
node src/main.js l1 --brand=히도

# 경로 지정
node src/main.js l1 \
  --input-dir=places-advanced \
  --output-dir=data/output/l1

# 디버그 모드
node src/main.js l1 --verbose
```

## 다음 단계

L1 완료 후 다음 작업을 진행할 수 있습니다:
- **L2**: AI 기반 키워드 확장 및 목표키워드 설정
- **L3**: 네이버 검색량 조회 및 경쟁도 분석
- **L4**: 최종 대표키워드 추천 및 우선순위 설정

## 문의 및 지원

이슈가 발생하거나 개선 사항이 있으면 로그 파일과 함께 문의해주세요:
- 로그 위치: `Place_Crawler/V1/logs/gui-server.log`
- 디버그 로그 탭에서 내보내기 가능
